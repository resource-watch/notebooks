{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapSPAM 2010 data \n",
    "\n",
    "In this notebook we download the data that we need from [MapSPAM](http://mapspam.info/data/)\n",
    "\n",
    "The SPAM (10 x 10 km grid-cell resolution) data is specifically based on the four variables which are calculated by the model: `physical area`, `harvest area`, `production` and `yield`, for each of the 42 crops, split by `rainfed` and `irrigated` production system, as well as the total combination of both.\n",
    "\n",
    "SPAM generates a large collection of data: ~800.000 pixels X 42 crops X 4 production systems X 4 variables = ~500 million records\n",
    "\n",
    "Please check the [methodology](http://mapspam.info/methodology/) section for a thorough explanation.\n",
    "\n",
    "**SPAM 2010 v1.0 Global Data (Latest)**\n",
    "\n",
    "Download pre-packaged SPAM 2010 v1.0 data and map files at the global level, as one separate file for each crop, production system, variable and format. The available formats are DBF and GeoTIFF. See the [ReadMe](https://s3.amazonaws.com/mapspam/2010/v1.0/ReadMe_v1r0_Global.txt) file first!\n",
    "\n",
    "* List of available SPAM variables:   \n",
    "\n",
    "|SPAM long name | SPAM short name |description|  \n",
    "|:---|:---|:---|  \n",
    "|PHYSICAL AREA| phys_area|Physical area is measured in hectare, and represents the actual area where a crop is grown, not counting how often production was harvested from it. Physical area is calculated for each  production system and crop, and the sum of all physical areas of the four production systems constitute the total physical area for that crop. The sum of the physical areas of all crops in a pixel may not be larger than the pixel size.|   \n",
    "|HARVESTED AREA|harv_area|Also measured in hectare, harvested area is at least as large as physical area, but sometimes more, since it also accounts for multiple harvests of a crop on the same plot. Like for physical area, the harvested area is calculated for each production system, and the sum of all harvested areas of all production systems in a pixel amount to the total harvested area of the pixel.|  \n",
    "|PRODUCTION| prod|Production, for each production system and crop, is calculated by multiplying area harvested with yield. It is measured in metric tons. The total production of a crop includes the production of all production systems of that crop.|  \n",
    "|YIELD| yield|Yield is a measure of productivity, the amount of production per harvested area, and is measured in kilogram/hectare. The total yield of a crop, when considering all production systems, is not the sum of the individual yields, but the weighted average of the 4 yields|  \n",
    "\n",
    "* List of available [crops](http://mapspam.info/wp-content/uploads/4-Methodology-Crops-of-SPAM-2005-2015-02-26.csv) \n",
    "\n",
    "|No. crt.| SPAM short name | SPAM long name |FAONAMES | GROUP|\n",
    "|:---|:---|:---|:---|:---|  \n",
    "|1 | whea | wheat                | wheat                                | cereals                       |\n",
    "|2 | rice | rice                 | rice                                 | cereals                       |\n",
    "|3 | maiz | maize                | maize                                | cereals                       |\n",
    "|4 | barl | barley               | barley                               | cereals                       |\n",
    "|5 | pmil | pearl millet         | millet                               | cereals                       |\n",
    "|6 | smil | small millet         | millet                               | cereals                       |\n",
    "|7 | sorg | sorghum              | sorghum                              | cereals                       |\n",
    "|8 | ocer | other cereals        | other cereals ++                     | cereals                       |\n",
    "|9 | pota | potato               | potato                               | roots&tubers or starchy roots |\n",
    "|10| swpo | sweet potato         | sweet potato                         | roots&tubers or starchy roots |\n",
    "|11| yams | yams                 | yam                                  | roots&tubers or starchy roots |\n",
    "|12| cass | cassava              | cassava                              | roots&tubers or starchy roots |\n",
    "|13| orts | other roots          | yautia ++                            | roots&tubers or starchy roots |\n",
    "|14| bean | bean                 | beans, dry                           | pulses                        |\n",
    "|15| chic | chickpea             | chickpea                             | pulses                        |\n",
    "|16| cowp | cowpea               | cowpea                               | pulses                        |\n",
    "|17| pige | pigeonpea            | pigeon pea                           | pulses                        |\n",
    "|18| lent | lentil               | lentils                              | pulses                        |\n",
    "|19| opul | other pulses         | broad beans ++                       | pulses                        |\n",
    "|20| soyb | soybean              | soybean                              | oilcrops                      |\n",
    "|21| grou | groundnut            | groundnut, with shell                | oilcrops                      |\n",
    "|22| cnut | coconut              | coconut                              | oilcrops                      |\n",
    "|23| oilp | oilpalm              | palmoil                              | oilcrops                      |\n",
    "|24| sunf | sunflower            | sunflower seed                       | oilcrops                      |\n",
    "|25| rape | rapeseed             | rapeseed                             | oilcrops                      |\n",
    "|26| sesa | sesameseed           | sesame seed                          | oilcrops                      |\n",
    "|27| ooil | other oil crops      | olives ++                            | oilcrops                      |\n",
    "|28| sugc | sugarcane            | sugar cane                           | sugar crops                   |\n",
    "|29| sugb | sugarbeet            | sugarbeet                            | sugar crops                   |\n",
    "|30| cott | cotton               | seed cotton                          | fibres                        |\n",
    "|31| ofib | other fibre crops    | other fibres ++                      | fibres                        |\n",
    "|32| acof | arabica coffee       | coffee                               | stimulant                     |\n",
    "|33| rcof | robusta coffee       | coffee                               | stimulant                     |\n",
    "|34| coco | cocoa                | cocoa                                | stimulant                     |\n",
    "|35| teas | tea                  | tea                                  | stimulant                     |\n",
    "|36| toba | tobacco              | tobacco leaves                       | stimulant                     |\n",
    "|37| bana | banana               | banana                               | fruits                        |\n",
    "|38| plnt | plantain             | plantain                             | fruits                        |\n",
    "|39| trof | tropical fruit       | oranges ++                           | fruits                        |\n",
    "|40| temf | temperate fruit      | apples ++                            | fruits                        |\n",
    "|41| vege | vegetables           | cabbages and other brassicas ++      | vegetables                    |\n",
    "|42| rest | rest of crops        | all individual other crops           |                               |\n",
    "\n",
    "* List of available production systems\n",
    "\n",
    "|name| production systems |\n",
    "|:---|:---|  \n",
    "|Irrigated|irrigated portion of crop|  \n",
    "|Rainfed|rainfed portion of crop|   \n",
    "|Rainfed|rainfed high inputs portion of crop| \n",
    "|Rainfed|rainfed low inputs portion of crop| \n",
    "|Total | all technologies together, ie complete crop| \n",
    "\n",
    "\n",
    "**SPAM 2010 data structure:**\n",
    "\n",
    "The SPAM 2010 data files are structured like this:\n",
    "\n",
    "- Base url: https://s3.amazonaws.com/mapspam/2010/v1.0/dbf/\n",
    "- Zip files: \n",
    "\n",
    "|File name| description |\n",
    "|:---|:---| \n",
    "|spam2010v1r0_global_harv_area.dbf.zip\t|SPAM area harvested, global pixels, files in 2 formats x 6 technologies, strucuture A, record type H |\n",
    "|spam2010v1r0_global_prod.dbf.zip\t\t|SPAM production, global pixels, files in 2 formats x 6 technologies, strucuture A, record type P     |\n",
    "\n",
    "- File names: \n",
    "\n",
    "    All files have standard names, which allow direct identification of variable and technology:\n",
    "    spam2010v1r0_global_v_t.dbf\n",
    "    \n",
    "    where\n",
    "    \n",
    "    v = variable\n",
    "    \n",
    "    t = technology\n",
    "    \n",
    "    - Variables (v):\n",
    "        \n",
    "| v  | SPAM name | \n",
    "|:---|:---|\n",
    "| harvested-area | harvested area |\n",
    "| production | production |\n",
    "    \n",
    "    - Technologies (t):\n",
    "     \n",
    "| t  | description | \n",
    "|:---|:---|\n",
    "|ti | irrigated portion of crop|\n",
    "|tr | rainfed portion of crop  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "from simpledbf import Dbf5\n",
    "import fiona\n",
    "import rtree\n",
    "from collections import OrderedDict\n",
    "from shapely.geometry import mapping, shape\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely.wkb \n",
    "from shapely.ops import cascaded_union\n",
    "from shapely.geometry import Polygon, Point, MultiPolygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "We download the `harvested area` and `production` variables for 2010 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl = 'https://s3.amazonaws.com/mapspam/2010/v1.0/dbf/'\n",
    "folder = '/Volumes/MacBook HD/data/aqueduct/data_source/spamdata2010/'\n",
    "variables = ['harv_area', 'prod']\n",
    "\n",
    "for variable in variables:\n",
    "    filename = 'spam2010v1r0_global'+'_'+variable+'.dbf.zip'\n",
    "    dataUrl=baseUrl+filename\n",
    "    response = requests.get(dataUrl, stream=True)\n",
    "    \n",
    "    file_output = folder + filename\n",
    "    print(filename)\n",
    "    with open(file_output, 'wb') as handle:\n",
    "        for chunk in tqdm(response.iter_content(chunk_size=128)):\n",
    "            handle.write(chunk)\n",
    "            \n",
    "    # uncompress zip file\n",
    "    with zipfile.ZipFile(file_output,\"r\") as zip_ref:\n",
    "        zip_ref.extractall(folder)\n",
    "      \n",
    "    # remove zip file\n",
    "    os.remove(file_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "### Read data\n",
    "\n",
    "We read only the next \n",
    "- Variables:\n",
    "    - Harvested area\n",
    "    - Production \n",
    "- Production systems:\n",
    "    - Irrigated\n",
    "    - Rainfed \n",
    "    \n",
    "and merge them all together in a single table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseFolder = '/Volumes/MacBook HD/data/aqueduct/data_source/spamdata2010/'\n",
    "variables_file = {'harv_area': 'harvested-area', 'prod': 'production'}\n",
    "production_types = {'harv_area': 'area', 'prod': 'prod'}\n",
    "\n",
    "irrigation = {'irrigated': 'ti', 'rainfed': 'tr'}\n",
    "suffix = {'irrigated': 'i', 'rainfed': 'r'}\n",
    "\n",
    "crops = {\"whea\": \"wheat\", \"rice\": \"rice\", \"maiz\": \"maize\", \"barl\": \"barley\", \"pmil\": \"pearl millet\", \n",
    "         \"smil\": \"small millet\", \"sorg\": \"sorghum\", \"ocer\": \"other cereals\", \"pota\": \"potato\", \n",
    "         \"swpo\": \"sweet potato\", \"yams\": \"yams\", \"cass\": \"cassava\", \"orts\": \"other roots\", \n",
    "         \"bean\": \"bean\", \"chic\": \"chickpea\", \"cowp\": \"cowpea\", \"pige\": \"pigeonpea\", \"lent\": \"lentil\", \n",
    "         \"opul\": \"other pulses\", \"soyb\": \"soybean\", \"grou\": \"groundnut\", \"cnut\": \"coconut\", \n",
    "         \"oilp\": \"oilpalm\", \"sunf\": \"sunflower\", \"rape\": \"rapeseed\", \"sesa\": \"sesameseed\", \n",
    "         \"ooil\": \"other oil crops\", \"sugc\": \"sugarcane\", \"sugb\": \"sugarbeet\", \"cott\": \"cotton\", \n",
    "         \"ofib\": \"other fibre crops\", \"acof\": \"arabica coffee\", \"rcof\": \"robusta coffee\", \n",
    "         \"coco\": \"cocoa\", \"teas\": \"tea\", \"toba\": \"tobacco\", \"bana\": \"banana\", \"plnt\": \"plantain\", \n",
    "         \"trof\": \"tropical fruit\", \"temf\": \"temperate fruit\", \"vege\": \"vegetables\", \"rest\": \"rest of crops\"}                           \n",
    "\n",
    "\n",
    "df_prod = pd.DataFrame(columns=['iso', 'prod_level', 'cell5m', 'name_cntr', 'name_adm1', 'name_adm2', 'unit_prod', 'crop', 'prod', 'irrigation'])\n",
    "df_area = pd.DataFrame(columns=['iso', 'prod_level', 'cell5m', 'name_cntr', 'name_adm1', 'name_adm2', 'unit_area', 'crop', 'area', 'irrigation'])\n",
    "\n",
    "for itype in irrigation.keys():\n",
    "    \n",
    "    df_type = pd.DataFrame(columns=['cell5m', 'crop', 'irrigation', 'area', 'prod', \n",
    "                               'unit_area', 'unit_prod', 'iso', 'name_cntr',\n",
    "                               'prod_level'\n",
    "                              ])\n",
    "    \n",
    "    for variable in variables_file.keys():\n",
    "        folder = 'spam2010v1r0_global'+'_'+variable+'.dbf'\n",
    "        filename = 'spam2010v1r0_global'+'_'+variables_file[variable]+'_'+irrigation[itype]+'.dbf'\n",
    "        \n",
    "        print(filename)\n",
    "        dbf = Dbf5(baseFolder+folder+'/'+filename, codec='cp1252')\n",
    "        df = dbf.to_dataframe()\n",
    "        df.columns = df.columns.str.lower()\n",
    "        \n",
    "        # Select columns\n",
    "        columns = list(dict((\"{}_{}\".format(k,suffix[itype]),v) for k,v in crops.items()))\n",
    "        columns.extend(['iso3', 'prod_level', 'cell5m', 'name_cntr', 'name_adm1', 'name_adm2', 'unit'])\n",
    "        df = df[columns]\n",
    "\n",
    "        # Change columns names\n",
    "        change_names = dict((\"{}_{}\".format(k,suffix[itype]),v) for k,v in crops.items())\n",
    "        change_names.update({'iso3': 'iso', 'unit': 'unit_'+production_types[variable]})\n",
    "        df.rename(columns=change_names, inplace=True)\n",
    "\n",
    "        # Unpivot DataFrame\n",
    "        df = pd.melt(df, id_vars=['iso', 'prod_level', 'cell5m', 'name_cntr', 'name_adm1', 'name_adm2', 'unit_'+production_types[variable]], \n",
    "                          var_name=\"crop\", value_name=production_types[variable])\n",
    "\n",
    "        # Sort by\n",
    "        df.sort_values(['iso', 'cell5m'], inplace=True)\n",
    "        df.sort_values(['iso', 'cell5m'], inplace=True)\n",
    "        \n",
    "        # Add irrigation column\n",
    "        df['irrigation'] = itype\n",
    "        \n",
    "        if variable == 'prod':\n",
    "            df_prod = pd.concat([df_prod, df])\n",
    "        else:\n",
    "            df_area = pd.concat([df_area, df])         \n",
    "\n",
    "# Merge Harvested area and Production DataFrames\n",
    "df_all = pd.merge(left=df_area, right=df_prod, how='left',\n",
    "                  on=['iso', 'prod_level', 'cell5m', 'name_cntr', 'name_adm1', 'name_adm2', 'crop', 'irrigation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data\n",
    "\n",
    "We will select all cells that have `Harvested area` bigger or equal to 10 ha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_all[df_all['area'] >= 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv('/Volumes/MacBook HD/data/aqueduct/dst/spam2010/data_filtered.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersection between the SPAM grid cells and the basins\n",
    "\n",
    "We will perform the clip between the `cell5M` geometries and the basins.\n",
    "\n",
    "If a `cell5M` falls into more than one basin then we will split the cell and compute the percentage of the cell covered by each basin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read `cell5M` geometries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell5m = gpd.read_file('/Volumes/MacBook HD/data/aqueduct/data_source/spamdata/spam_cells/April_2013_IMPACT_Cell5M.shp')\n",
    "cell5m.columns = [x.lower() for x in cell5m.columns]\n",
    "cell5m.rename(columns={'cell5m_id_': 'cell5m', 'iso3code': 'iso'}, inplace=True)\n",
    "cell5m.sort_values(['iso', 'cell5m'], inplace=True)\n",
    "\n",
    "# convert the 'cell5m' column to object\n",
    "cell5m['cell5m'] = cell5m['cell5m'].astype('int') \n",
    "#cell5m['cell5m'] = cell5m['cell5m'].astype('object') \n",
    "\n",
    "cell5m.drop(columns=['iso', 'alloc_key'], inplace=True)\n",
    "\n",
    "cell5m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read basins for baseline water risk indicators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_geo = gpd.read_file('/Volumes/MacBook HD/data/aqueduct/data_source/AQ_2_water_risk_atlas/Y2018M12D06_RH_Master_Shape_V01/output_V02/Y2018M12D06_RH_Master_Shape_V01.shp')\n",
    "baseline_geo.drop(columns=['aqid', 'gid_1', 'pfaf_id', 'type'], inplace=True)\n",
    "baseline_geo['geometry'] = baseline_geo['geometry'].apply(lambda x: x.buffer(0))\n",
    "baseline_geo.to_file('/Volumes/MacBook HD/data/aqueduct/dst/spam2010/baseline_geo/baseline_geo.shp')\n",
    "baseline_geo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read basins for projected water risk indicators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_geo = gpd.read_file('/Volumes/MacBook HD/data/aqueduct/data_source/AQ_2_water_risk_atlas/wri_subcatchements/wri_subcatchements.shp')\n",
    "projected_geo.drop(columns=['cartodb_id', 'gu', 'country', 'basin_name', 'iso', 'area_km2', 'down_basin'], inplace=True)\n",
    "projected_geo = projected_geo[projected_geo.geometry.notnull()]\n",
    "projected_geo['geometry'] = projected_geo['geometry'].apply(lambda x: x.buffer(0))\n",
    "projected_geo.to_file('/Volumes/MacBook HD/data/aqueduct/dst/spam2010/projected_geo/projected_geo.shp')\n",
    "projected_geo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We use geopandas’s R-tree spatial index to find which basins lie within each grid cell**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of an individual cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rtree_intersect_cell(gdf, grid, cell5m):\n",
    "    columns = list(gdf.columns)\n",
    "    columns.append('percentage')\n",
    "    gdf_new = gpd.GeoDataFrame(columns=columns)\n",
    "    \n",
    "    cell = grid[grid['cell5m'] == cell5m].geometry.iloc[0]\n",
    "    sindex = gdf.sindex\n",
    "\n",
    "    # basins that intersect with the cell\n",
    "    possible_matches_index = list(sindex.intersection(cell.bounds))\n",
    "    possible_matches = gdf.iloc[possible_matches_index]\n",
    "    # intersection between the basin and the cell\n",
    "    intersection = possible_matches.intersection(cell)\n",
    "    # percentage of the cell covered by each basin\n",
    "    percentage = intersection.apply(lambda x: x.area/cell.area)\n",
    "    # precise matches where percentage > 0\n",
    "    precise_matches = possible_matches[possible_matches.index.isin(percentage[percentage > 0].index)]\n",
    "\n",
    "    for column in gdf_new.columns:\n",
    "        if (column != 'geometry') and (column != 'percentage'):\n",
    "            gdf_new[column]=precise_matches[column]\n",
    "        else:\n",
    "            if column == 'geometry':\n",
    "                gdf_new[column]=intersection.loc[precise_matches.index]\n",
    "            if column == 'percentage':\n",
    "                gdf_new[column]=percentage.loc[precise_matches.index]\n",
    "            \n",
    "    fig, ax = plt.subplots(figsize=[5,5])\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    possible_matches.plot(ax=ax, edgecolor='r')\n",
    "    precise_matches.plot(ax=ax, color='g',  edgecolor='r')\n",
    "    gdf_new.plot(ax=ax,color='r', edgecolor='w')\n",
    "    gpd.GeoDataFrame(data={'geometry': [cell]}).plot(ax=ax,color='w', edgecolor='k', alpha=0.1)\n",
    "    plt.xlim(cell.bounds[0]-0.2,cell.bounds[2]+0.2)\n",
    "    plt.ylim(cell.bounds[1]-0.2,cell.bounds[3]+0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtree_intersect_cell(baseline_geo, cell5m, 3065782)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over the cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rtree_intersect(gdf, grid, path):\n",
    "    columns = list(gdf.columns)\n",
    "    columns.append('percentage')\n",
    "    columns.append('cell5m')\n",
    "    gdf_all = gpd.GeoDataFrame(columns=columns)\n",
    "    sindex = gdf.sindex\n",
    "    # we iterate over the cells\n",
    "    for n, cell in enumerate(tqdm(grid.geometry)):\n",
    "        gdf_new = gpd.GeoDataFrame(columns=columns)\n",
    "        # basins that intersect with the cell\n",
    "        possible_matches_index = list(sindex.intersection(cell.bounds))\n",
    "        possible_matches = gdf.iloc[possible_matches_index]\n",
    "        # intersection between the basin and the cell\n",
    "        intersection = possible_matches.intersection(cell)\n",
    "        # percentage of the cell covered by each basin\n",
    "        percentage = intersection.apply(lambda x: x.area/cell.area)\n",
    "        # precise matches where percentage > 0\n",
    "        precise_matches = possible_matches[possible_matches.index.isin(percentage[percentage > 0].index)]\n",
    "        \n",
    "        for column in gdf_new.columns:\n",
    "            if (column != 'geometry') and (column != 'percentage') and (column != 'cell5m'):\n",
    "                gdf_new[column]=precise_matches[column]\n",
    "            else:\n",
    "                if column == 'geometry':\n",
    "                    gdf_new[column]=intersection.loc[precise_matches.index]\n",
    "                if column == 'percentage':\n",
    "                    gdf_new[column]=percentage.loc[precise_matches.index]\n",
    "                if column == 'cell5m':\n",
    "                    gdf_new[column]=grid['cell5m'].iloc[n]\n",
    "                    \n",
    "        gdf_all = pd.concat([gdf_all, gdf_new])\n",
    "        if n % 100000 == 0:\n",
    "            gdf_all.to_file(path)\n",
    "    \n",
    "    gdf_all.to_file(path)\n",
    "    return gdf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rtree_intersect_fiona(gdf_path, grid, out_path):\n",
    "    gdf = gpd.read_file(gdf_path)\n",
    "    columns = list(gdf.columns)\n",
    "    columns.append('percentage')\n",
    "    columns.append('cell5m')\n",
    "\n",
    "    properties = columns.copy()\n",
    "    properties.remove('geometry')\n",
    "\n",
    "    sindex = gdf.sindex\n",
    "    \n",
    "    with fiona.open(gdf_path, 'r') as layer1:\n",
    "        # We copy schema and add the  new property for the new resulting shp\n",
    "        crss=layer1.crs\n",
    "        schema = layer1.schema.copy()\n",
    "        for property in properties: \n",
    "            schema['properties'][property] = 'str:80'\n",
    "    \n",
    "        with fiona.open(out_path, 'w', 'ESRI Shapefile', schema, crs=crss) as layer2:\n",
    "    \n",
    "            # we iterate over the cells\n",
    "            for n, cell in enumerate(tqdm(grid.geometry)):\n",
    "                gdf_new = gpd.GeoDataFrame(columns=columns)\n",
    "                # basins that intersect with the cell\n",
    "                possible_matches_index = list(sindex.intersection(cell.bounds))\n",
    "                possible_matches = gdf.iloc[possible_matches_index]\n",
    "                # intersection between the basin and the cell\n",
    "                intersection = possible_matches.intersection(cell)\n",
    "                # percentage of the cell covered by each basin\n",
    "                percentage = intersection.apply(lambda x: x.area/cell.area)\n",
    "                # precise matches where percentage > 0\n",
    "                precise_matches = possible_matches[possible_matches.index.isin(percentage[percentage > 0].index)]\n",
    "        \n",
    "                for column in gdf_new.columns:\n",
    "                    if (column != 'geometry') and (column != 'percentage') and (column != 'cell5m'):\n",
    "                        gdf_new[column]=precise_matches[column]\n",
    "                    else:\n",
    "                        if column == 'geometry':\n",
    "                            gdf_new[column]=intersection.loc[precise_matches.index]\n",
    "                        if column == 'percentage':\n",
    "                            gdf_new[column]=percentage.loc[precise_matches.index]\n",
    "                        if column == 'cell5m':\n",
    "                            gdf_new[column]=grid['cell5m'].iloc[n]\n",
    "                        \n",
    "                gdf_new[properties] = gdf_new[properties].astype('object')\n",
    "                for i in range(len(gdf_new)):\n",
    "                    # Add the content to the right schema in the new shp\n",
    "                    layer2.write({\n",
    "                        'properties': OrderedDict(gdf_new[properties].iloc[i].to_dict()),\n",
    "                        'geometry': mapping(gdf_new['geometry'].iloc[i])\n",
    "                    });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_path = '/Volumes/MacBook HD/data/aqueduct/dst/spam2010/baseline_geo/baseline_geo.shp'\n",
    "out_path = '/Volumes/MacBook HD/data/aqueduct/dst/spam2010/cell5m_baseline/cell5m_baseline.shp'\n",
    "rtree_intersect_fiona(gdf_path, cell5m, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_path = '/Volumes/MacBook HD/data/aqueduct/dst/spam2010/projected_geo/projected_geo.shp'\n",
    "out_path = '/Volumes/MacBook HD/data/aqueduct/dst/spam2010/cell5m_projected/cell5m_projected.shp'\n",
    "rtree_intersect_fiona(gdf_path, cell5m, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read `cell5M` geometries intersected with baseline basins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell5M_baseline = gpd.read_file('/Volumes/MacBook HD/data/aqueduct/dst/spam2010/cell5m_baseline/cell5m_baseline.shp')\n",
    "cell5M_baseline['aq30_id'] = cell5M_baseline['aq30_id'].astype('int64')\n",
    "cell5M_baseline['percentage'] = cell5M_baseline['percentage'].astype('float64')\n",
    "cell5M_baseline['percentage'] = cell5M_baseline['percentage'].apply(lambda x: round(x,4))\n",
    "cell5M_baseline['cell5m'] = cell5M_baseline['cell5m'].astype('int')\n",
    "cell5M_baseline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read `cell5M` geometries intersected with projected basins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell5M_projected = gpd.read_file('/Volumes/MacBook HD/data/aqueduct/dst/spam2010/cell5m_projected/cell5m_projected.shp')\n",
    "cell5M_projected['basinid'] = cell5M_projected['basinid'].astype('int64')\n",
    "cell5M_projected['percentage'] = cell5M_projected['percentage'].astype('float64')\n",
    "cell5M_projected['percentage'] = cell5M_projected['percentage'].apply(lambda x: round(x,4))\n",
    "cell5M_projected['cell5m'] = cell5M_projected['cell5m'].astype('int')\n",
    "cell5M_projected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add `cell5M` geometry and baisin ids to the SPAM data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.read_csv('/Volumes/MacBook HD/data/aqueduct/dst/spam2010/data_filtered.csv')\n",
    "df_filtered.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "gdf_filtered = gpd.GeoDataFrame(df_filtered)\n",
    "gdf_filtered['cell5m'] = gdf_filtered['cell5m'].astype('int')\n",
    "gdf_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add baseline basins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge GeoDataFrames\n",
    "filtered_cell5M_baseline = pd.merge(left=gdf_filtered, right=cell5M_baseline, how='left', on='cell5m')\n",
    "\n",
    "# Multiply the area and the production with the percentage of each cell fraction\n",
    "def f(*x):\n",
    "    return x[0]*x[1]\n",
    "filtered_cell5M_baseline['prod'] = filtered_cell5M_baseline[['prod','percentage']].apply(lambda x: f(*x), axis=1).round(1)\n",
    "filtered_cell5M_baseline['area'] = filtered_cell5M_baseline[['area','percentage']].apply(lambda x: f(*x), axis=1).round(1)\n",
    "filtered_cell5M_baseline.drop(columns=['percentage'], inplace=True)\n",
    "\n",
    "# Drop duplicates\n",
    "filtered_cell5M_baseline.drop_duplicates(subset=['cell5m', 'crop', 'irrigation', 'prod', 'aq30_id'], inplace=True)\n",
    "\n",
    "# Save GeoDataFrame\n",
    "#filtered_cell5M_baseline.to_file('/Volumes/MacBook HD/data/aqueduct/dst/spam2010/data_baseline/data_baseline.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add projected basins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge GeoDataFrames\n",
    "filtered_cell5M_projected = pd.merge(left=gdf_filtered, right=cell5M_projected, how='left', on='cell5m')\n",
    "\n",
    "# Multiply the area and the production with the percentage of each cell fraction\n",
    "def f(*x):\n",
    "    return x[0]*x[1]\n",
    "filtered_cell5M_projected['prod'] = filtered_cell5M_projected[['prod','percentage']].apply(lambda x: f(*x), axis=1).round(1)\n",
    "filtered_cell5M_projected['area'] = filtered_cell5M_projected[['area','percentage']].apply(lambda x: f(*x), axis=1).round(1)\n",
    "filtered_cell5M_projected.drop(columns=['percentage'], inplace=True)\n",
    "\n",
    "# Drop duplicates\n",
    "filtered_cell5M_projected.drop_duplicates(subset=['cell5m', 'crop', 'irrigation', 'prod', 'basinid'], inplace=True)\n",
    "\n",
    "# Save GeoDataFrame\n",
    "#filtered_cell5M_projected.to_file('/Volumes/MacBook HD/data/aqueduct/dst/spam2010/data_projected/data_projected.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking of the crops in each cell\n",
    "For a given `cell5m`, basin and irrigation type we perform a ranking of the most productive crops, where 1 corresponds to the most productive one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline basins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_baseline = filtered_cell5M_baseline[['cell5m', 'crop', 'irrigation', 'prod', 'aq30_id']].copy()\n",
    "\n",
    "rank_baseline_new = pd.DataFrame(columns=['cell5m', 'crop', 'irrigation', 'prod', 'aq30_id', 'rank'])\n",
    "\n",
    "for irrigation in ['irrigated', 'rainfed']:\n",
    "    rank = rank_baseline[rank_baseline['irrigation'] == irrigation]\n",
    "    \n",
    "    rank.sort_values(['cell5m'], inplace=True)\n",
    "    cell5m_unique = rank['cell5m'].unique()\n",
    "    cell5m_unique.sort()\n",
    "    \n",
    "    cell = []\n",
    "    basin = []\n",
    "    prod = []\n",
    "    ranking = []\n",
    "\n",
    "    for cell5m in  tqdm(cell5m_unique):\n",
    "        df = rank[rank['cell5m'] == cell5m]\n",
    "        for aq30_id in df['aq30_id'].unique():\n",
    "            df_aq = df[df['aq30_id'] == aq30_id]\n",
    "        \n",
    "            cell.extend([cell5m] * len(df_aq))\n",
    "            basin.extend([aq30_id] * len(df_aq))\n",
    "            prod.extend(list(df_aq['prod']))\n",
    "            ranking.extend(list(df_aq['prod'].rank(ascending=False)))\n",
    "        \n",
    "    df_rank = pd.DataFrame({'cell5m': cell, 'aq30_id': basin, 'prod': prod, 'rank': ranking}) \n",
    "    \n",
    "\n",
    "    rank_new = pd.merge(left=rank, right=df_rank, how='inner', on=['cell5m', 'aq30_id', 'prod'])   \n",
    "    \n",
    "    rank_baseline_new = pd.concat([rank_baseline_new, rank_new])\n",
    "    \n",
    "    rank_baseline_new.to_csv('/Volumes/MacBook HD/data/aqueduct/dst/spam2010/rank_baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_baseline = pd.read_csv('/Volumes/MacBook HD/data/aqueduct/dst/spam2010/rank_baseline.csv')\n",
    "rank_baseline.drop(columns='Unnamed: 0', inplace=True)\n",
    "rank_baseline['rank'] = rank_baseline['rank'].astype('int64')\n",
    "rank_baseline.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cell5M_baseline.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cell5M_rank_baseline = pd.merge(left=filtered_cell5M_baseline, right=rank_baseline, on=['cell5m', 'crop', 'irrigation', 'prod', 'aq30_id'])\n",
    "filtered_cell5M_rank_baseline['rank'] = filtered_cell5M_rank_baseline['rank'].astype('int64')\n",
    "filtered_cell5M_rank_baseline['aq30_id'] = filtered_cell5M_rank_baseline['aq30_id'].astype('int64')\n",
    "filtered_cell5M_rank_baseline.drop(columns=['name_adm1', 'name_adm2'], inplace=True)\n",
    "filtered_cell5M_rank_baseline.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cell5M_rank_baseline.to_file('/Volumes/MacBook HD/data/aqueduct/dst/spam2010/cell5m_baseline_rank/filtered_cell5M_rank_baseline.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Projected basins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_projected = filtered_cell5M_projected[['cell5m', 'crop', 'irrigation', 'prod', 'basinid']].copy()\n",
    "\n",
    "rank_projected_new = pd.DataFrame(columns=['cell5m', 'crop', 'irrigation', 'prod', 'basinid', 'rank'])\n",
    "\n",
    "for irrigation in ['irrigated', 'rainfed']:\n",
    "    rank = rank_projected[rank_projected['irrigation'] == irrigation]\n",
    "    \n",
    "    rank.sort_values(['cell5m'], inplace=True)\n",
    "    cell5m_unique = rank['cell5m'].unique()\n",
    "    cell5m_unique.sort()\n",
    "    \n",
    "    cell = []\n",
    "    basin = []\n",
    "    prod = []\n",
    "    ranking = []\n",
    "\n",
    "    for cell5m in  tqdm(cell5m_unique):\n",
    "        df = rank[rank['cell5m'] == cell5m]\n",
    "        for basinid in df['basinid'].unique():\n",
    "            df_aq = df[df['basinid'] == basinid]\n",
    "        \n",
    "            cell.extend([cell5m] * len(df_aq))\n",
    "            basin.extend([basinid] * len(df_aq))\n",
    "            prod.extend(list(df_aq['prod']))\n",
    "            ranking.extend(list(df_aq['prod'].rank(ascending=False)))\n",
    "        \n",
    "    df_rank = pd.DataFrame({'cell5m': cell, 'basinid': basin, 'prod': prod, 'rank': ranking}) \n",
    "    \n",
    "\n",
    "    rank_new = pd.merge(left=rank, right=df_rank, how='inner', on=['cell5m', 'basinid', 'prod'])   \n",
    "    \n",
    "    rank_projected_new = pd.concat([rank_projected_new, rank_new])\n",
    "    \n",
    "    rank_projected_new.to_csv('/Volumes/MacBook HD/data/aqueduct/dst/spam2010/rank_projected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_projected = pd.read_csv('/Volumes/MacBook HD/data/aqueduct/dst/spam2010/rank_projected.csv')\n",
    "rank_projected.drop(columns='Unnamed: 0', inplace=True)\n",
    "rank_projected['rank'] = rank_projected['rank'].astype('int64')\n",
    "rank_projected.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cell5M_projected.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cell5M_rank_projected = pd.merge(left=filtered_cell5M_projected, right=rank_projected, on=['cell5m', 'crop', 'irrigation', 'prod', 'basinid'])\n",
    "filtered_cell5M_rank_projected['rank'] = filtered_cell5M_rank_projected['rank'].astype('int64')\n",
    "filtered_cell5M_rank_projected['basinid'] = filtered_cell5M_rank_projected['basinid'].astype('int64')\n",
    "filtered_cell5M_rank_projected.drop(columns=['name_adm1', 'name_adm2'], inplace=True)\n",
    "filtered_cell5M_rank_projected.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cell5M_rank_projected.to_file('/Volumes/MacBook HD/data/aqueduct/dst/spam2010/cell5m_projected_rank/filtered_cell5M_rank_projected.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split table\n",
    "We split the tables in x datasets to make it uploable to a carto account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_table(basefile, filename, size):\n",
    "    \"\"\"\n",
    "    this function splits a table in x datasets to make it uploable to a carto account\n",
    "    \"\"\"\n",
    "    dataset = gpd.read_file(basefile+filename+'.shp')\n",
    "    for i in range(int(np.ceil(dataset.shape[0]/size))):\n",
    "        split_dataset_name = filename+'_'+str(i)\n",
    "        print(split_dataset_name)\n",
    "        os.mkdir(basefile+split_dataset_name)\n",
    "        full_path = basefile+split_dataset_name+'/'+split_dataset_name+'.shp'\n",
    "        dataset.iloc[i*size:(i+1)*size].to_file(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basefile = '/Volumes/MacBook HD/data/aqueduct/dst/spam2010/cell5m_baseline_rank/'\n",
    "split_table(basefile, 'filtered_cell5M_rank_baseline', 2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basefile = '/Volumes/MacBook HD/data/aqueduct/dst/spam2010/cell5m_projected_rank/'\n",
    "split_table(basefile, 'filtered_cell5M_rank_projected', 2000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge table in carto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline basins**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "SELECT the_geom, aq30_id, area, cell5m, crop, irrigation, iso, name_cntr, prod, prod_level, rank, unit_area, unit_prod from filtered_cell5m_rank_baseline_0\n",
    "union all\n",
    "SELECT the_geom, aq30_id, area, cell5m, crop, irrigation, iso, name_cntr, prod, prod_level, rank, unit_area, unit_prod from filtered_cell5m_rank_baseline_1\n",
    "union all\n",
    "SELECT the_geom, aq30_id, area, cell5m, crop, irrigation, iso, name_cntr, prod, prod_level, rank, unit_area, unit_prod from filtered_cell5m_rank_baseline_2\n",
    "union all\n",
    "SELECT the_geom, aq30_id, area, cell5m, crop, irrigation, iso, name_cntr, prod, prod_level, rank, unit_area, unit_prod from filtered_cell5m_rank_baseline_3\n",
    "union all\n",
    "SELECT the_geom, aq30_id, area, cell5m, crop, irrigation, iso, name_cntr, prod, prod_level, rank, unit_area, unit_prod from filtered_cell5m_rank_baseline_4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Projected basins**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "SELECT the_geom, basinid, area, cell5m, crop, irrigation, iso, name_cntr, prod, prod_level, rank, unit_area, unit_prod from filtered_cell5m_rank_projected_0\n",
    "union all\n",
    "SELECT the_geom, basinid, area, cell5m, crop, irrigation, iso, name_cntr, prod, prod_level, rank, unit_area, unit_prod from filtered_cell5m_rank_projected_1\n",
    "union all\n",
    "SELECT the_geom, basinid, area, cell5m, crop, irrigation, iso, name_cntr, prod, prod_level, rank, unit_area, unit_prod from filtered_cell5m_rank_projected_2\n",
    "union all\n",
    "SELECT the_geom, basinid, area, cell5m, crop, irrigation, iso, name_cntr, prod, prod_level, rank, unit_area, unit_prod from filtered_cell5m_rank_projected_3\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
