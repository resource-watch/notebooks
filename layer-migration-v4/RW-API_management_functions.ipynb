{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb0fd80",
   "metadata": {},
   "source": [
    "# RW - API management functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a5815c",
   "metadata": {},
   "source": [
    "These functions will cover the functions need to manage assets within the RW-API and will be base on the code develop for [OW migration from staging to db](https://github.com/resource-watch/notebooks/blob/develop/ResourceWatch/example_migrate_script.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "234a4612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: devtools[pygments] in /opt/conda/lib/python3.8/site-packages (0.8.0)\n",
      "Requirement already satisfied: asttokens<3.0.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from devtools[pygments]) (2.0.5)\n",
      "Requirement already satisfied: executing<1.0.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from devtools[pygments]) (0.8.2)\n",
      "Requirement already satisfied: Pygments>=2.2.0 in /opt/conda/lib/python3.8/site-packages (from devtools[pygments]) (2.10.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from asttokens<3.0.0,>=2.0.0->devtools[pygments]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%run './pydantic_data_classes_rw.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08ea455a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "builtins==None\n",
      "builtins==None\n",
      "requests_toolbelt.sessions==None\n",
      "types==None\n",
      "json==2.0.9\n",
      "logging==0.5.1.2\n",
      "getpass==None\n"
     ]
    }
   ],
   "source": [
    "from requests_toolbelt import sessions\n",
    "from requests_toolbelt.auth.handler import AuthHandler\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from datetime import datetime\n",
    "\n",
    "import types\n",
    "import json\n",
    "import logging\n",
    "import getpass\n",
    "\n",
    "from pydantic import parse_obj_as\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "print('\\n'.join(f'{module.__name__}=={getattr(module, \"__version__\", None)}' for  i, module in globals().items() if isinstance(module, types.ModuleType)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48eb6529",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6dbe61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TIMEOUT = 60 # seconds\n",
    "\n",
    "class TimeoutHTTPAdapter(HTTPAdapter):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.timeout = DEFAULT_TIMEOUT\n",
    "        if \"timeout\" in kwargs:\n",
    "            self.timeout = kwargs[\"timeout\"]\n",
    "            del kwargs[\"timeout\"]\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def send(self, request, **kwargs):\n",
    "        timeout = kwargs.get(\"timeout\")\n",
    "        if timeout is None:\n",
    "            kwargs[\"timeout\"] = self.timeout\n",
    "        return super().send(request, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12160fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auth(session):\n",
    "    '''\n",
    "    Authenticates into the RW API\n",
    "    '''\n",
    "    print(f'You are login into {bcolors.HEADER}{bcolors.BOLD}RW api{bcolors.ENDC}')\n",
    "    \n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    payload = json.dumps({ 'email': f'{input(f\"Email: \")}',\n",
    "                           'password': f'{getpass.getpass(prompt=\"Password: \")}'})\n",
    "    response = session.post('/auth/login',  headers = headers,  data = payload)\n",
    "    \n",
    "    print(f'{bcolors.OKGREEN}Successfully logged into RW api{bcolors.ENDC}')\n",
    "    \n",
    "    return response.json().get('data').get('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ad1e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rwApiSession(serverUrl=\"https://api.resourcewatch.org\"):\n",
    "    '''\n",
    "    Creates a sesion object for making calls to the RW api.\n",
    "    '''\n",
    "    retries = Retry(total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])\n",
    "    \n",
    "    assert_status_hook = lambda response, *args, **kwargs: response.raise_for_status()\n",
    "\n",
    "    httpsSession = sessions.BaseUrlSession(base_url = serverUrl )\n",
    "    \n",
    "    httpsSession.mount(\"https://\", TimeoutHTTPAdapter(max_retries=retries))\n",
    "    httpsSession.hooks[\"response\"] = [assert_status_hook]\n",
    "    \n",
    "    token = auth(httpsSession)\n",
    "    \n",
    "    httpsSession.headers['Authorization'] = f'Bearer {token}'\n",
    "    \n",
    "    return httpsSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d114af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyAssetBody(asset, excludeList=['createdAt', 'updatedAt','clonedHost', 'errorMessage', 'taskId', \n",
    "                                      'status', 'sources','userId', 'slug', 'dataset', 'layer', \n",
    "                                      'widget', 'metadata', 'vocabulary']):\n",
    "    '''\n",
    "    Copy a body dict to a new dict excluding some keys or not defined values.\n",
    "    '''\n",
    "    response = {}\n",
    "    response.update(asset)\n",
    "    \n",
    "    for key, value in asset.items():\n",
    "        if (key in excludeList or value is None or (type(value) == dict and len(value) == 0) ):\n",
    "            response.pop(key, None)\n",
    "    \n",
    "    if 'provider' in response.keys() and response['provider'] =='cartodb':\n",
    "        response.pop('tableName', None)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8be32c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAssetList(session, application: List='rw', env='production', includes='layer'):\n",
    "    '''\n",
    "    Gets a list of assets from the selected env or from the constrained dataset list\n",
    "    For our needs we will ignore other includer than layer.\n",
    "    '''\n",
    "    url = '/v1/dataset'\n",
    "    payload={\n",
    "        'env':'production',\n",
    "        'application':'rw',\n",
    "        'status':'saved',\n",
    "        'includes':'layer',\n",
    "        'page[size]':100\n",
    "    }\n",
    "    response = []\n",
    "    data = session.get(url, params=payload).json()\n",
    "    \n",
    "    response.extend(data['data'])\n",
    "    \n",
    "    # If pagination is needed we will access the data chunk by chunk\n",
    "    if data['meta']['total-pages'] > 1:\n",
    "        for n in range(2, data['meta']['total-pages'] + 1):\n",
    "            payload['page[number]'] = n\n",
    "            response.extend(session.get(url, params=payload).json()['data'])\n",
    "    \n",
    "    return parse_obj_as(List[Dataset], response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6edde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayerList(session):\n",
    "    '''\n",
    "    Gets a list of assets from the selected env or from the layers.\n",
    "    '''\n",
    "    url = '/v1/layer'\n",
    "    payload={\n",
    "        'env':'production',\n",
    "        'application':'rw',\n",
    "        'status':'saved',\n",
    "        'page[size]':100\n",
    "    }\n",
    "    response = []\n",
    "    data = session.get(url, params=payload).json()\n",
    "    \n",
    "    response.extend(data['data'])\n",
    "    \n",
    "    # If pagination is needed we will access the data chunk by chunk\n",
    "    if data['meta']['total-pages'] > 1:\n",
    "        for n in range(2, data['meta']['total-pages'] + 1):\n",
    "            payload['page[number]'] = n\n",
    "            response.extend(session.get(url, params=payload).json()['data'])\n",
    "    return parse_obj_as(List[Layer], response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cef5daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backupAssets(session, env = 'prod'):\n",
    "    '''\n",
    "    save a backup of production data just in case we need to recreate it again\n",
    "    '''\n",
    "    data = getAssetList(session)\n",
    "\n",
    "    with open(f'RW_{env}_backup_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7160a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOrUpdatedataset(session, dataset, toEnv = 'staging', destinationDatasetId = None):\n",
    "    '''\n",
    "    Copy the dataset from one env to the other\n",
    "    '''\n",
    "    if dataset.get('type')!='dataset':\n",
    "        return None\n",
    "    \n",
    "    baseDatasetUrl = f'/v1/dataset'\n",
    "\n",
    "    body = {'dataset': copyAssetBody(dataset.get('attributes'))}\n",
    "    \n",
    "    logger.debug(body)\n",
    "    \n",
    "    # Upsert operation\n",
    "    if destinationDatasetId: \n",
    "        return session.patch(f'{baseDatasetUrl}/{destinationDatasetId}',json = body['dataset']).json()\n",
    "    else:\n",
    "        return session.post(baseDatasetUrl, body['dataset']).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e133649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOrUpdateLayer(session, datasetId, layer, toEnv = 'staging', destinationLayerId = None):\n",
    "    '''\n",
    "    Copy the layer from one env to the other\n",
    "    '''\n",
    "    if layer.get('type')!='layer':\n",
    "        return None\n",
    "    baseDatasetUrl = f'/v1/dataset/{datasetId}/layer'\n",
    "\n",
    "    body = copyAssetBody(layer.get('attributes'))\n",
    "    \n",
    "    logger.debug(body)\n",
    "    \n",
    "    # Upsert operation\n",
    "    if destinationLayerId: \n",
    "        return session.patch(f'{baseDatasetUrl}/{destinationLayerId}', json = body['dataset']).json()\n",
    "    else:\n",
    "        return session.post(baseDatasetUrl, body['dataset']).json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
