{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "from pprint import pprint\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "region=ee.Geometry.Rectangle([-179, -79, 179, 79],\"EPSG:4326\")\n",
    "image_categoric = ee.Image('JRC/GSW1_0/GlobalSurfaceWater').clip(region)\n",
    "image_continuous = ee.Image('LEDAPS/L7_PRE/LE70230391999217GNC00').clip(region)\n",
    "#geom = ee.Geometry('{\"type\":\"Polygon\",\"coordinates\":[[[-180,-90],[180,-90],[180,90],[-180,90],[-180,-90]]]}')\n",
    "\n",
    "#pprint(image_categoric.getInfo())\n",
    "#print(image_continuous.getInfo()['bands'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical imagery; visual acceptance applied to bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Query to accept:  \n",
    "`select st_valuecount(rast, band_name,avoidnodata_value=true) from table_name`  \n",
    "* response:\n",
    "```json  \n",
    "{....\n",
    " data: [ {'1': 1587812.5294117641,\n",
    "  '12': 101301105.41176467,\n",
    "  '2': 607895.1764705883,\n",
    "  '3': 142714.52941176473,\n",
    "  '4': 32528.88235294118,\n",
    "  '5': 23573.29411764706,\n",
    "  '6': 28119.70588235294,\n",
    "  '7': 1905.0,\n",
    "  '8': 49.0}}} ...} \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'change_abs': 43403,\n",
       " 'change_norm': 43398,\n",
       " 'max_extent': 43403,\n",
       " 'occurrence': 43402,\n",
       " 'recurrence': 43403,\n",
       " 'seasonality': 42860,\n",
       " 'transition': 43394}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_args = {\n",
    "        'reducer': ee.Reducer.count(),\n",
    "        #'geometry':region,\n",
    "        'bestEffort': True\n",
    "    }\n",
    "image_categoric.reduceRegion(**reduce_args).getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'change_abs': 171,\n",
       " 'change_norm': 142,\n",
       " 'max_extent': 2,\n",
       " 'occurrence': 101,\n",
       " 'recurrence': 85,\n",
       " 'seasonality': 13,\n",
       " 'transition': 11}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_args = {\n",
    "        'reducer': ee.Reducer.countDistinct().unweighted(),\n",
    "        #'geometry':region,\n",
    "        'bestEffort': True\n",
    "    }\n",
    "image_categoric.reduceRegion(**reduce_args).getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seasonality': {'1': 1587904.0,\n",
      "                 '12': 101310426.0,\n",
      "                 '2': 607929.0,\n",
      "                 '3': 142726.0,\n",
      "                 '4': 32533.0,\n",
      "                 '5': 23578.0,\n",
      "                 '6': 28120.0,\n",
      "                 '7': 1905.0,\n",
      "                 '8': 49.0,\n",
      "                 'null': 3669312750.0}}\n"
     ]
    }
   ],
   "source": [
    "reduce_args = {\n",
    "        'reducer': ee.Reducer.frequencyHistogram().unweighted(),\n",
    "        #'geometry':region,\n",
    "        'maxPixels': 9000000000000000000,\n",
    "        'bestEffort': True\n",
    "    }\n",
    "\n",
    "pprint(image_categoric.select('seasonality').reduceRegion(**reduce_args).getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reduce_args = {\n",
    "        'reducer': ee.Reducer.frequencyHistogram(),\n",
    "        #'geometry':region,\n",
    "        'maxPixels': 100000000000,\n",
    "        'bestEffort': True\n",
    "    }\n",
    "image_categoric.select('change_norm').reduceRegion(**reduce_args).getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "geojson={u'crs': u'EPSG:4326', u'type': u'FeatureCollection', u'features': [{u'geometry': {'type': 'Polygon', 'coordinates': [[[-43.39599609375, -4.740675384778361], [-43.39599609375, -4.959615024698014], [-43.17626953125, -4.806364708499984], [-43.39599609375, -4.740675384778361]]]}, u'type': u'Feature', u'properties': {}}]}\n",
    "#{\"features\":[{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-4.4000244140625,40.14109012528468],[-2.955322265625,40.14109012528468],[-2.955322265625,40.65563874006118],[-4.4000244140625,40.65563874006118],[-4.4000244140625,40.14109012528468]]]}}]}\n",
    "\n",
    "#{'crs': 'EPSG:4326', 'type': 'FeatureCollection', 'features': [{'geometry': {'type': 'Polygon', 'coordinates': [[[-43.39599609375, -4.740675384778361], [-43.39599609375, -4.959615024698014], [-43.17626953125, -4.806364708499984], [-43.39599609375, -4.740675384778361]]]}}]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feat=ee.FeatureCollection(geojson.get('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SQL2GEE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-03b181b88389>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msql2gee\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSQL2GEE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SQL2GEE'"
     ]
    }
   ],
   "source": [
    "from sql2gee import SQL2GEE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm /Users/alicia/miniconda3/lib/python3.6/site-packages/sql2gee/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from __future__ import print_function, division\r\n",
      "from cached_property import cached_property\r\n",
      "\r\n",
      "import ee\r\n",
      "import re\r\n",
      "import ast\r\n",
      "import sqlparse\r\n",
      "from sqlparse.tokens import Keyword\r\n",
      "from sqlparse.sql import Identifier, IdentifierList, Function, Parenthesis, Comparison\r\n",
      "\r\n",
      "_default_geojson = {u'crs':'EPSG:4326',\r\n",
      "                    u'features': [\r\n",
      "                                    {u'geometry': dict(coordinates=[[[[1.40625,\r\n",
      "                                                           85.1114157806266],\r\n",
      "                                                          [0,\r\n",
      "                                                           -84.99010018023479],\r\n",
      "                                                          [-180,\r\n",
      "                                                           -85.05112877980659],\r\n",
      "                                                          [-180,\r\n",
      "                                                           85.1114157806266]]],\r\n",
      "                                                        [[[179.296875,\r\n",
      "                                                           85.05112877980659],\r\n",
      "                                                          [1.40625,\r\n",
      "                                                           85.05112877980659],\r\n",
      "                                                          [0.703125,\r\n",
      "                                                           -84.99010018023479],\r\n",
      "                                                          [179.296875,\r\n",
      "                                                           -84.86578186731522]]]],\r\n",
      "                                    evenOdd= True,\r\n",
      "                                    type= u'MultiPolygon'),\r\n",
      "                                    u'type': u'Feature'}\r\n",
      "                                ],\r\n",
      "                    u'type': u'FeatureCollection'}\r\n",
      "\r\n",
      "class SQL2GEE(object):\r\n",
      "    \"\"\"\r\n",
      "    Takes an SQL-like query and relates it to Google's Earth Engine syntax (specifically the Python 2.7 GEE API).\r\n",
      "    Designed to perform operations on two types of geo-objects, Polygons (Feature Collections) or Rasters (Images).\r\n",
      "    For the rasters there are only a specific number of valid operations (retrieve metadata, histogram data, or get\r\n",
      "    summary statistics). We use postgis-like functions as the syntax to do this, and check to see if this is given in\r\n",
      "    the sql string to detect the user intention.\r\n",
      "\r\n",
      "    If geojson data is provided, we will assume that a user intends for us to subset an image, by these data.\r\n",
      "    \"\"\"\r\n",
      "    def __init__(self, sql, geojson=None, flags=None):\r\n",
      "        self._raw = sql\r\n",
      "        self._parsed = sqlparse.parse(sql)[0]\r\n",
      "        self.geojson = self._geojson_to_featurecollection(geojson)\r\n",
      "        self.flags = flags  # <-- Will be used in a later version of the code\r\n",
      "        self._filters = {\r\n",
      "            '<': ee.Filter().lt,\r\n",
      "            '<=': ee.Filter().lte,\r\n",
      "            '>': ee.Filter().gt,\r\n",
      "            '>=': ee.Filter().gte,\r\n",
      "            '<>': ee.Filter().neq,\r\n",
      "            '=': ee.Filter().eq,\r\n",
      "            '%LIKE%': ee.Filter().stringContains,\r\n",
      "            '%LIKE': ee.Filter().stringEndsWith,\r\n",
      "            'LIKE%': ee.Filter().stringStartsWith,\r\n",
      "            'LIKE': ee.Filter().eq,\r\n",
      "        }\r\n",
      "        self._comparisons = {\r\n",
      "            'AND': ee.Filter().And,\r\n",
      "            'OR': ee.Filter().Or\r\n",
      "        }\r\n",
      "\r\n",
      "    def _geojson_to_featurecollection(self, geojson):\r\n",
      "        \"\"\"If Geojson kwarg is recieved or ST_GEOMFROMGEOJSON sql argument is used,\r\n",
      "        (containing geojson data) convert it into a useable E.E. object.\"\"\"\r\n",
      "        if 'st_geomfromgeojson' in self._raw.lower():\r\n",
      "            geojson = self.geojson_from_STGeomFromGeoJSON()\r\n",
      "        #print(geojson)\r\n",
      "        if isinstance(geojson, dict):\r\n",
      "            assert geojson.get('features') != None, \"Expected key not found in item passed to geojoson\"\r\n",
      "            return ee.FeatureCollection(geojson.get('features'))\r\n",
      "        else:\r\n",
      "            return None\r\n",
      "\r\n",
      "    def geojson_from_STGeomFromGeoJSON(self):\r\n",
      "        \"\"\"Extract geojson dictionary, and crs code from a complex SQL command using Regex\"\"\"\r\n",
      "        geojson = {u'features': [],\r\n",
      "                   u'type': u'FeatureCollection'}\r\n",
      "        matchObj = re.match(r\"(.*) ST_INTERSECTS((.*))\", self._raw, re.M | re.I)\r\n",
      "        codestring = matchObj.group(2)\r\n",
      "        crs_code = re.search(r'(\\),.*\\),)', codestring, re.I).group(0)[2:-2]\r\n",
      "        assert int(crs_code) == 4326, \"Project {code} not yet supported\".format(code=crs_code)\r\n",
      "        searchObj = re.search(r'\\{.*\\}', codestring, re.I)\r\n",
      "        d_string = searchObj.group(0)\r\n",
      "        d = ast.literal_eval(d_string)\r\n",
      "        if int(crs_code) == 4326:\r\n",
      "            geojson[u'crs'] = u'EPSG:4326'\r\n",
      "        else:\r\n",
      "            assert False, ('{crs} currently unsupported'.format(crs=crs_code))\r\n",
      "        geojson['features'].append({u'type':u'Feature',u'properties':{},u'geometry': d})\r\n",
      "        \r\n",
      "        return geojson\r\n",
      "\r\n",
      "\r\n",
      "    @cached_property\r\n",
      "    def _is_image_request(self):\r\n",
      "        \"\"\"Detect if the user intends to use an image (True) or Feature collection (False). In the future a flag will\r\n",
      "        be used to do this.\"\"\"\r\n",
      "        tmp = [r for r in re.split('[\\(\\*\\)\\s]', self._raw.lower()) if r != '']\r\n",
      "        tmp = set(tmp)\r\n",
      "        image_keywords = {'st_histogram', 'st_metadata', 'st_summarystats', 'st_bandmetadata', 'st_valuecount'}\r\n",
      "        intersect = tmp.intersection(image_keywords)\r\n",
      "        if len(intersect) == 0:\r\n",
      "            return False\r\n",
      "        elif len(intersect) == 1:\r\n",
      "            return True\r\n",
      "        else:\r\n",
      "            raise ValueError(\"Found multiple image-type keywords. Unsure of action.\")\r\n",
      "\r\n",
      "    @cached_property\r\n",
      "    def _band_names(self):\r\n",
      "        if self._is_image_request:\r\n",
      "            return ee.Image(self.target_data).bandNames().getInfo()\r\n",
      "\r\n",
      "    @property\r\n",
      "    def _reduce_image(self):\r\n",
      "        \"\"\" Construct a combined reducer dictionary and pass it to a ReduceRegion().getInfo() command.\r\n",
      "        If a geometry has been passed to SQL2GEE, it will be passed to ensure only a subset of the band is examined.\r\n",
      "        \"\"\"\r\n",
      "        d={}\r\n",
      "        d['bestEffort'] = True\r\n",
      "        if self.geojson:\r\n",
      "            d['geometry'] = self.geojson\r\n",
      "        d['reducer'] = ee.Reducer.count().combine(ee.Reducer.sum(), outputPrefix='', sharedInputs=True\r\n",
      "                        ).combine(ee.Reducer.mean(), outputPrefix='', sharedInputs=True).combine(\r\n",
      "                        ee.Reducer.sampleStdDev(), outputPrefix='', sharedInputs=True).combine(ee.Reducer.min(),\r\n",
      "                        outputPrefix='', sharedInputs=True).combine(ee.Reducer.max(), outputPrefix='',\r\n",
      "                        sharedInputs=True).combine(ee.Reducer.percentile([25, 75]), outputPrefix='', sharedInputs=True)\r\n",
      "        return ee.Image(self.target_data).reduceRegion(**d).getInfo()\r\n",
      "\r\n",
      "    @cached_property\r\n",
      "    def _band_IQR(self):\r\n",
      "        \"\"\"Return a dictionary object with the InterQuartileRange (Q3 - Q1) per band.\"\"\"\r\n",
      "        if self._is_image_request:\r\n",
      "            iqr = {}\r\n",
      "            for band in self._band_names:\r\n",
      "                tmp = self._reduce_image[band + '_p75'] - self._reduce_image[band + '_p25']\r\n",
      "                iqr[band] = tmp\r\n",
      "                del tmp\r\n",
      "            return iqr\r\n",
      "\r\n",
      "    @cached_property\r\n",
      "    def _metadata(self):\r\n",
      "        \"\"\"Property that holds the Metadata dictionary returned from Earth Engine.\"\"\"\r\n",
      "        if self._is_image_request:\r\n",
      "            return ee.Image(self.target_data).getInfo()\r\n",
      "\r\n",
      "    @property\r\n",
      "    def st_metadata(self):\r\n",
      "        \"\"\"The image property Metadata dictionary returned from Earth Engine.\"\"\"\r\n",
      "        metadata=self._metadata['properties'].copy()\r\n",
      "        metadata.update({\"bands\": self._metadata['bands']})\r\n",
      "        assert metadata != None, \"No metadata available\"\r\n",
      "        \r\n",
      "        return metadata\r\n",
      "\r\n",
      "\r\n",
      "    def extract_postgis_arguments(self, argument_string, list_of_expected):\r\n",
      "        \"\"\"Expects a string list of arguments passed to postgis function, and an ordered list of keys needed\r\n",
      "        In this way, we should be able to handle any postgis argument arrangements:\r\n",
      "        value_string, ordered keyword list: ['raster', 'band_id', 'n_bins'])\r\n",
      "        \"\"\"\r\n",
      "        assert len(argument_string) > 0, \"No arguments passed to postgis function\"\r\n",
      "        value_list = argument_string.split(',')\r\n",
      "        assert len(value_list) == len(list_of_expected), \"argument string from postgis not equal to list of expected keys\"\r\n",
      "        return_values = []\r\n",
      "        for expected, argument in zip(list_of_expected, value_list):\r\n",
      "            if expected is 'raster':\r\n",
      "                return_values.append(str(argument.strip()))\r\n",
      "            if expected is 'band_id':\r\n",
      "                if str(argument.strip().strip(\"'\")) in  self._band_names:\r\n",
      "                    nband = str(argument.strip().strip(\"'\")) \r\n",
      "                                       \r\n",
      "                else:\r\n",
      "                    numband = int(argument.strip()) - 1  # a zero index for self._band_list\r\n",
      "                    nband = self._band_names[numband]\r\n",
      "                    \r\n",
      "                assert nband in self._band_names, '{0} is not a valid band name in the requested data.'.format(nband)\r\n",
      "                return_values.append(nband)\r\n",
      "            if expected is 'n_bins':\r\n",
      "                try:\r\n",
      "                    bins = int(argument.strip())\r\n",
      "                    assert bins > 0, \"Bin number for ST_HISTOGRAM() must be > 0: bins = {0} passed.\".format(bins)\r\n",
      "                except:\r\n",
      "                    assert argument.strip().lower() == 'auto',\"Either pass int number of desired bins, or auto\"\r\n",
      "                    bins = None\r\n",
      "                return_values.append(bins)\r\n",
      "            if expected is 'bool':\r\n",
      "                bool_arg = None\r\n",
      "                if argument.strip().lower() == 'true': bool_arg = True\r\n",
      "                if argument.strip().lower() == 'false': bool_arg = False\r\n",
      "                assert isinstance(bool_arg, bool), \"Boolean not correctly set\"\r\n",
      "                return_values.append(bool_arg)\r\n",
      "        assert len(return_values) == len(list_of_expected),'Failed to identify all keywords :('\r\n",
      "        return return_values\r\n",
      "\r\n",
      "    @property\r\n",
      "    def st_bandmetadata(self):\r\n",
      "        \"\"\"Return only metadata for a specifically requested band, like postgis function\"\"\"\r\n",
      "        for function in self.group_functions:\r\n",
      "            if function['function'].lower() == \"st_bandmetadata\":\r\n",
      "                values = function['value']\r\n",
      "                assert len(values) > 0, \"raster string and bandnum integer (or band key string) must be provided\"\r\n",
      "                _, nband = self.extract_postgis_arguments(values, ['raster','band_id'])\r\n",
      "        for band in self._metadata.get('bands'):\r\n",
      "            if band.get('id') == nband:\r\n",
      "                tmp_meta = band\r\n",
      "        return tmp_meta\r\n",
      "\r\n",
      "    @cached_property\r\n",
      "    def st_valuecount(self):\r\n",
      "        \"\"\"Return only metadata for a specifically requested band, like postgis function\"\"\"\r\n",
      "        #tmp_dic = {}\r\n",
      "        for function in self.group_functions:\r\n",
      "            if function['function'].lower() == \"st_valuecount\":\r\n",
      "                values = function['value']\r\n",
      "                assert len(values) > 0, \"raster string and bandnum integer (or band key string) must be provided\"\r\n",
      "                _, band_of_interest, no_drop_no_data_val = self.extract_postgis_arguments(values, ['raster','band_id', 'bool'])\r\n",
      "        d = {}\r\n",
      "        d['reducer'] = ee.Reducer.frequencyHistogram().unweighted()\r\n",
      "        d['bestEffort'] = True\r\n",
      "        d['maxPixels'] =  9000000000\r\n",
      "        if self.geojson:\r\n",
      "            d['geometry'] = self.geojson\r\n",
      "        tmp_response = ee.Image(self.target_data).select(band_of_interest).reduceRegion(**d).getInfo()\r\n",
      "        if no_drop_no_data_val != True:\r\n",
      "            try:\r\n",
      "                del tmp_response[band_of_interest]['null']\r\n",
      "            except KeyError:\r\n",
      "                pass\r\n",
      "        #else:\r\n",
      "            \r\n",
      "            #tmp_dic[band_of_interest] = tmp_response[band_of_interest]\r\n",
      "        return tmp_response\r\n",
      "\r\n",
      "    @cached_property\r\n",
      "    def summary_stats(self):\r\n",
      "        \"\"\"Return a dictionary object of summary stats like the postgis function ST_SUMMARYSTATS().\"\"\"\r\n",
      "        d = {}\r\n",
      "        for band in self._band_names:\r\n",
      "            d[band] = {'count': self._reduce_image[band+'_count'],\r\n",
      "                       'sum': self._reduce_image[band+'_sum'],\r\n",
      "                       'mean': self._reduce_image[band+'_mean'],\r\n",
      "                       'stdev':self._reduce_image[band+'_stdDev'],\r\n",
      "                       'min': self._reduce_image[band+'_min'],\r\n",
      "                       'max': self._reduce_image[band+'_max']\r\n",
      "                       }\r\n",
      "        return d\r\n",
      "\r\n",
      "    def _default_histogram_inputs(self, band_name):\r\n",
      "        \"\"\"Return the optimum histogram min, max, bins, using Freedman-Diaconis method, to be used by default\r\n",
      "        band_name is the dictionary key (that relates to self._band_names)\r\n",
      "        \"\"\"\r\n",
      "        band_max = self._reduce_image[band_name +'_max']\r\n",
      "        band_count = self._reduce_image[band_name +'_count']\r\n",
      "        band_min = self._reduce_image[band_name +'_min']\r\n",
      "        band_iqr = self._band_IQR[band_name]\r\n",
      "        band_n = self._reduce_image[band_name +'_count']\r\n",
      "        bin_width = (2 * band_iqr * (band_n ** (-1/3)))\r\n",
      "        try:\r\n",
      "            num_bins = int((band_max - band_min) / bin_width)\r\n",
      "        except ZeroDivisionError:\r\n",
      "            num_bins = band_count ** 0.5  # as a last-resort, use the square root of the counts to set-bin size\r\n",
      "        return band_min, band_max, num_bins\r\n",
      "\r\n",
      "    @cached_property\r\n",
      "    def histogram(self):\r\n",
      "        \"\"\"Retrieve ST_HISTOGRAM()-like info. This will return a dictionary object with bands as keys, and for each\r\n",
      "        band a nested list of (2xn) for bin and frequency. If the user wants us to use the optimum bin number,\r\n",
      "        they can pass n-bins 'auto' instead of an integer.\r\n",
      "        \"\"\"\r\n",
      "        tmp_dic = {}\r\n",
      "        for function in self.group_functions:\r\n",
      "            if function['function'].lower() == \"st_histogram\":\r\n",
      "                values = function['value']\r\n",
      "                assert len(values) > 0, \"ST_Histogram must be called with arguments\"\r\n",
      "        hist_args = self.extract_postgis_arguments(values, ['raster','band_id', 'n_bins', 'bool'])\r\n",
      "        _, band_of_interest, input_bin_num, dont_flip_order = hist_args\r\n",
      "        input_min, input_max, auto_bins = self._default_histogram_inputs(band_of_interest)\r\n",
      "        if not input_bin_num:\r\n",
      "            input_bin_num = auto_bins\r\n",
      "        d = {}\r\n",
      "        input_max = input_max + 1  # In EE counting the min -> max range is exc. at max, so need to increment here.\r\n",
      "        d['reducer'] = ee.Reducer.fixedHistogram(input_min, input_max, input_bin_num)\r\n",
      "        d['bestEffort'] = True\r\n",
      "        if self.geojson:\r\n",
      "            d['geometry'] = self.geojson\r\n",
      "        tmp_response = ee.Image(self.target_data).select(band_of_interest).reduceRegion(**d).getInfo()\r\n",
      "        if dont_flip_order:\r\n",
      "            tmp_dic[band_of_interest] = tmp_response[band_of_interest]\r\n",
      "        else:\r\n",
      "            tmp_dic[band_of_interest] = tmp_response[band_of_interest][:][::-1]\r\n",
      "        return tmp_dic\r\n",
      "\r\n",
      "\r\n",
      "    @property\r\n",
      "    def target_data(self):\r\n",
      "        \"\"\"Set target_data property using sql tokens, assuming it\r\n",
      "        is the first token of type Identifier after the 'FROM' keyword\r\n",
      "        also of type Identifier. If not found, raise an Exception.\"\"\"\r\n",
      "        from_seen = False\r\n",
      "        exception_1 = Exception('Unable to determine dataset in SQL query statement.')\r\n",
      "        for item in self._parsed.tokens:\r\n",
      "            if from_seen:\r\n",
      "                if len(item.value.strip()) > 0:\r\n",
      "                    return self.remove_quotes(str(item))\r\n",
      "                elif item.ttype is Keyword:\r\n",
      "                    raise exception_1\r\n",
      "            elif item.ttype is Keyword and str(item).upper() == 'FROM':\r\n",
      "                from_seen = True\r\n",
      "        raise exception_1\r\n",
      "\r\n",
      "    @property\r\n",
      "    def fields(self):\r\n",
      "        \"\"\"A list of all fields in SQL query. If the FROM keyword is\r\n",
      "        encountered the list is immediately returned.\r\n",
      "        \"\"\"\r\n",
      "        field_list = []\r\n",
      "        for t in self._parsed.tokens:\r\n",
      "            is_keyword = t.ttype is Keyword\r\n",
      "            is_from = str(t).upper() == 'FROM'\r\n",
      "            if is_keyword and is_from:\r\n",
      "                return field_list\r\n",
      "            elif isinstance(t, Identifier):\r\n",
      "                field_list.append(str(t))\r\n",
      "            elif isinstance(t, IdentifierList):\r\n",
      "                for identity in t.tokens:\r\n",
      "                    if isinstance(identity, Identifier):\r\n",
      "                        field_list.append(str(identity))\r\n",
      "        return field_list\r\n",
      "\r\n",
      "    @property\r\n",
      "    def group_functions(self):\r\n",
      "        \"\"\"Returns the group function with column names specified in the query:\r\n",
      "        e.g. from sql input of 'select count(pepe) from mytable', a dictionary of\r\n",
      "        {'function': 'COUNT', 'value': 'pepe'} should be returned by self.group_functions\"\"\"\r\n",
      "        group_list = []\r\n",
      "        for t in self._parsed.tokens:\r\n",
      "            if t.ttype is Keyword and t.value.upper() == 'FROM':\r\n",
      "                return group_list\r\n",
      "            elif isinstance(t, Function):\r\n",
      "                group_list.append(self.token_to_dictionary(t))\r\n",
      "            elif isinstance(t, IdentifierList):\r\n",
      "                for identity in t.tokens:\r\n",
      "                    if isinstance(identity, Function):\r\n",
      "                        group_list.append(self.token_to_dictionary(identity))\r\n",
      "        return group_list\r\n",
      "\r\n",
      "    @staticmethod\r\n",
      "    def token_to_dictionary(token_list):\r\n",
      "        \"\"\" Receives a token e.g.('count(pepe)') and converts it into a dict\r\n",
      "        with key:values for function and value .\"\"\"\r\n",
      "        assert isinstance(token_list, sqlparse.sql.Function), 'unexpected datatype'\r\n",
      "        d = {}\r\n",
      "        for t in token_list:\r\n",
      "            if isinstance(t, Identifier):\r\n",
      "                d['function'] = str(t).upper()\r\n",
      "            elif isinstance(t, Parenthesis):\r\n",
      "                value = t.value.replace('(', '').replace(')', '').strip()\r\n",
      "                d['value'] = value\r\n",
      "        return d\r\n",
      "\r\n",
      "    @cached_property\r\n",
      "    def _image(self):\r\n",
      "        \"\"\"Performs a diffrent Image operation depending on sql request.\"\"\"\r\n",
      "        if self._is_image_request:\r\n",
      "            for func in self.group_functions:\r\n",
      "                if func[\"function\"].lower() == 'st_histogram':\r\n",
      "                    return self.histogram\r\n",
      "                if func[\"function\"].lower() == 'st_metadata':\r\n",
      "                    return self.st_metadata\r\n",
      "                if func[\"function\"].lower() == 'st_bandmetadata':\r\n",
      "                    return self.st_bandmetadata\r\n",
      "                if func[\"function\"].lower() == 'st_summarystats':\r\n",
      "                    return self.summary_stats\r\n",
      "                if func[\"function\"].lower() == 'st_valuecount':\r\n",
      "                    return self.st_valuecount\r\n",
      "\r\n",
      "    @cached_property\r\n",
      "    def _feature_collection(self):\r\n",
      "        \"\"\"Return the G.E.E. FeatureCollection object with all filter, groups, and functions applied\"\"\"\r\n",
      "        fc = ee.FeatureCollection(self.target_data)\r\n",
      "        if self.where:\r\n",
      "            fc = fc.filter(self.where)\r\n",
      "        if self.group_functions:\r\n",
      "            for group in self.group_functions:\r\n",
      "                fc = self.apply_group(fc, group)\r\n",
      "        select = self.fields\r\n",
      "        if select and len(select) > 0 and not select[0] == '*':\r\n",
      "            fc = fc.select(select)\r\n",
      "        if self.limit:\r\n",
      "            fc = fc.limit(self.limit)\r\n",
      "        return fc\r\n",
      "\r\n",
      "    @property\r\n",
      "    def where(self):\r\n",
      "        \"\"\"Returns filter object obtained from where of the query in GEE format\"\"\"\r\n",
      "        val, tmp = self._parsed.token_next_by(i=sqlparse.sql.Where)\r\n",
      "        if tmp:\r\n",
      "            return self.parse_conditions(tmp.tokens)\r\n",
      "        return None\r\n",
      "\r\n",
      "    @property\r\n",
      "    def limit(self):\r\n",
      "        \"\"\"If LIMIT keyword set, this returns an integer to limit the maximum return from a feature collection query\"\"\"\r\n",
      "        watch_for_limit = False\r\n",
      "        for i in list(self._parsed):\r\n",
      "            if i.ttype is Keyword and i.value.lower() == \"LIMIT\".lower():\r\n",
      "                watch_for_limit = True\r\n",
      "            if watch_for_limit and i.ttype is sqlparse.tokens.Literal.Number.Integer:\r\n",
      "                limit_value = int(i.value)\r\n",
      "                assert limit_value >= 1, 'Limit must be >= 1'\r\n",
      "                return limit_value\r\n",
      "\r\n",
      "    def apply_group(self, fc, group):\r\n",
      "        \"\"\"Given a fc (feature_collection) object and group operation, return a\r\n",
      "        new fc object, extended by a method of the feature grouping operation.\"\"\"\r\n",
      "        if not self._is_image_request:\r\n",
      "            if group['function'] == 'COUNT':\r\n",
      "                return fc.aggregate_count(group['value'])\r\n",
      "            elif group['function'] == 'MAX':\r\n",
      "                return fc.aggregate_max(group['value'])\r\n",
      "            elif group['function'] == 'MIN':\r\n",
      "                return fc.aggregate_min(group['value'])\r\n",
      "            elif group['function'] == 'SUM':\r\n",
      "                return fc.aggregate_sum(group['value'])\r\n",
      "            elif group['function'] == 'AVG':\r\n",
      "                return fc.aggregate_mean(group['value'])\r\n",
      "            elif group['function'] == 'FIRST':\r\n",
      "                return fc.aggregate_first(group['value'])\r\n",
      "            elif group['function'] == 'VAR':\r\n",
      "                return fc.aggregate_sample_var(group['value'])\r\n",
      "            elif group['function'] == 'STDEV':\r\n",
      "                return fc.aggregate_sample_sd(group['value'])\r\n",
      "            else:\r\n",
      "                raise ValueError(\"Unknown group function attempted: \", group['function'])\r\n",
      "\r\n",
      "    @staticmethod\r\n",
      "    def remove_quotes(input_str):\r\n",
      "        \"\"\"Checks the first and last characters of an input_str to see if they are quotation marks [' or \"], if so\r\n",
      "        the function will strip them and return the string.\r\n",
      "        :type input_str: str\"\"\"\r\n",
      "        starts_with_quotation = input_str[0] in ['\"', \"'\"]\r\n",
      "        ends_with_quotation = input_str[-1] in ['\"', \"'\"]\r\n",
      "        if starts_with_quotation and ends_with_quotation:\r\n",
      "            return input_str[1: -1]\r\n",
      "        else:\r\n",
      "            return input_str\r\n",
      "\r\n",
      "    def parse_comparison(self, comparison):\r\n",
      "        values = []\r\n",
      "        comparator = None\r\n",
      "        for item in comparison.tokens:\r\n",
      "            if isinstance(item, Identifier):\r\n",
      "                values.append(self.remove_quotes(item.value))\r\n",
      "            elif item.ttype is sqlparse.tokens.Comparison:\r\n",
      "                comparator = item.value\r\n",
      "            elif not item.is_whitespace:\r\n",
      "                if item.ttype is sqlparse.tokens.Number.Integer:\r\n",
      "                    values.append(int(item.value))\r\n",
      "                elif item.ttype is sqlparse.tokens.Number.Float:\r\n",
      "                    values.append(float(item.value))\r\n",
      "                else:\r\n",
      "                    values.append(self.remove_quotes(item.value))\r\n",
      "        if comparator:\r\n",
      "            return self._filters[comparator](values[0], values[1])\r\n",
      "\r\n",
      "    def generate_like(self, left, comp, right, exist_not):\r\n",
      "        if comp.value.upper() == 'LIKE':\r\n",
      "            filter = None\r\n",
      "            if right.strip().startswith('%') and right.strip().endswith('%'):\r\n",
      "                filter = self._filters['%' + comp.value.upper() + '%'](left, right[1:len(right) - 1])\r\n",
      "            elif right.strip().startswith('%'):\r\n",
      "                filter = self._filters['%' + comp.value.upper()](left, right[1:len(right)])\r\n",
      "            elif right.strip().endswith('%'):\r\n",
      "                filter = self._filters[comp.value.upper() + '%'](left, right[0:len(right) - 1])\r\n",
      "            else:\r\n",
      "                filter = self._filters[comp.value.upper()](left, right)\r\n",
      "\r\n",
      "            if exist_not:\r\n",
      "                return filter.Not()\r\n",
      "            return filter\r\n",
      "        else:\r\n",
      "            raise Exception(comp.value + ' not supported')\r\n",
      "\r\n",
      "    @staticmethod\r\n",
      "    def generate_in(left, comp, right, exist_not):\r\n",
      "        filter = ee.Filter().inList(left, right)\r\n",
      "        if exist_not:\r\n",
      "            return filter.Not()\r\n",
      "        return filter\r\n",
      "\r\n",
      "    @staticmethod\r\n",
      "    def generate_is(left, comp, right, ):\r\n",
      "        if right.upper() == 'NULL':\r\n",
      "            return ee.Filter().eq(left, 'null')\r\n",
      "        elif right.upper().startswith('NOT') and right.upper().endswith('NULL'):\r\n",
      "            return ee.Filter().neq(left, 'null')\r\n",
      "        else:\r\n",
      "            raise Exception('IS only support NULL value')\r\n",
      "\r\n",
      "    def parse_list(self, tokens):\r\n",
      "        values = []\r\n",
      "        for item in tokens:\r\n",
      "            if isinstance(item, Identifier):\r\n",
      "                values.append(self.remove_quotes(item.value))\r\n",
      "            elif not item.is_whitespace and item.value != ',':\r\n",
      "                if item.ttype is sqlparse.tokens.Number.Integer:\r\n",
      "                    values.append(int(item.value))\r\n",
      "                elif item.ttype is sqlparse.tokens.Number.Float:\r\n",
      "                    values.append(float(item.value))\r\n",
      "                else:\r\n",
      "                    values.append(self.remove_quotes(item.value))\r\n",
      "        return values\r\n",
      "\r\n",
      "    def parse_conditions(self, tokens):\r\n",
      "        filters = []\r\n",
      "        comparison = None\r\n",
      "        sub_comparison = None\r\n",
      "        leftValue = None\r\n",
      "        exist_not = False\r\n",
      "        for item in tokens:\r\n",
      "            if isinstance(item, Comparison):\r\n",
      "                filter = self.parse_comparison(item)\r\n",
      "                if exist_not:\r\n",
      "                    filter = filter.Not()\r\n",
      "                filters.append(filter)\r\n",
      "            elif item.ttype is Keyword and (item.value.upper() == 'AND' or item.value.upper() == 'OR'):\r\n",
      "                comparison = self._comparisons[item.value.upper()]\r\n",
      "            elif isinstance(item, Parenthesis):\r\n",
      "                filter = self.parse_conditions(item.tokens)\r\n",
      "                if isinstance(filter, ee.Filter):\r\n",
      "                    filters.append(filter)\r\n",
      "                elif type(filter) is list:\r\n",
      "                    filters.append(self.generate_in(leftValue, sub_comparison, filter, exist_not))\r\n",
      "                    leftValue = None\r\n",
      "                    sub_comparison = None\r\n",
      "                    exist_not = False\r\n",
      "            elif item.ttype is Keyword and (item.value.upper() == 'LIKE' or item.value.upper() == 'IN' or item.value.upper() == 'IS'):\r\n",
      "                sub_comparison = item\r\n",
      "            elif item.ttype is Keyword and item.value.upper() == 'NOT':\r\n",
      "                exist_not = True\r\n",
      "            elif isinstance(item, IdentifierList):\r\n",
      "                return self.parse_list(item.tokens)\r\n",
      "            elif item.ttype is None or (item.ttype is Keyword and (item.value.upper() == 'NULL' or item.value.upper().startswith('NOT'))):\r\n",
      "                if leftValue is None:\r\n",
      "                    leftValue = item.value\r\n",
      "                else:\r\n",
      "                    if sub_comparison.value.upper() == 'LIKE':\r\n",
      "                        filters.append(self.generate_like(leftValue, sub_comparison, self.remove_quotes(item.value), exist_not))\r\n",
      "                    elif sub_comparison.value.upper() == 'IS':\r\n",
      "                        filters.append(self.generate_is(leftValue, sub_comparison, self.remove_quotes(item.value)))\r\n",
      "                    sub_comparison = None\r\n",
      "                    leftValue = None\r\n",
      "                    exist_not = False\r\n",
      "            if comparison and len(filters) == 2:\r\n",
      "                statement = comparison(filters[0], filters[1])\r\n",
      "                if exist_not:\r\n",
      "                    statement = statement.Not()\r\n",
      "                    exist_not = False\r\n",
      "                filters = [statement]\r\n",
      "                comparison = None\r\n",
      "        return filters[0]\r\n",
      "\r\n",
      "\r\n",
      "    @cached_property\r\n",
      "    def response(self):\r\n",
      "        \"\"\"Execute the GEE object in GEE Server. This is the function that, when called, actually sends the SQL\r\n",
      "        request (which was converted to GEE-speak) to Google's servers for execution and returns the result.\"\"\"\r\n",
      "        ## This logic will be changed to instead execute the self.r , which will be made up of base + modifiers,\r\n",
      "        # So it can be either and Image() or FeatureCollection() type function.\r\n",
      "        if self._is_image_request:\r\n",
      "            try:\r\n",
      "                return self._image\r\n",
      "            except ee.EEException:\r\n",
      "                # If we hit the image composite bug then add a global region to group the image together and try again\r\n",
      "                return SQL2GEE(sql=self._raw, geojson=_default_geojson)._image\r\n",
      "        else:\r\n",
      "            return self._feature_collection.getInfo()\r\n"
     ]
    }
   ],
   "source": [
    "%cat /Users/alicia/miniconda3/lib/python3.6/site-packages/sql2gee/sql2gee.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "2",
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
