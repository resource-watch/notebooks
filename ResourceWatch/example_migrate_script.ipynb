{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migration and sync of assets between prod and staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will copy from one env to the other, will keep the match between IDs and we could potentially copy it back to prod from staging if we needed to\n",
    "\n",
    "First thing we'd need to do is make a copy. Then there are new datasets being added right now- is the best process for them to add it to Prod and copy to stg, or to upload it into stg\n",
    "\n",
    "Vizz would pass the script to WRI, we'd run it everytime we wanted to change anything over.\n",
    "WRI preference is to create in production, then copy into staging.\n",
    "If there are any changes needed to the datasets once they are in stg, the dataset will be updated in production, and then the script will copy the updates into staging.\n",
    "Vizz will be taking regular backups as well here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are the functions we need to create and sync assets from staging to production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import requests as re\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_server = \"https://staging-api.globalforestwatch.org\"\n",
    "prod_server = \"https://api.resourcewatch.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auth(env='prod'):\n",
    "    serverUrl = {\n",
    "        'prod': staging_server,\n",
    "        'staging': prod_server\n",
    "    }\n",
    "    print(f'You are login into {bcolors.HEADER}{bcolors.BOLD}{env}{bcolors.ENDC}')\n",
    "    with re.Session() as s:\n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        payload = json.dumps({ 'email': f'{input(f\"{bcolors.BOLD}Email: {bcolors.ENDC}\")}',\n",
    "                               'password': f'{getpass.getpass(prompt=\"Password: \")}'})\n",
    "        response = s.post(f'{serverUrl[env]}/auth/login',  headers = headers,  data = payload)\n",
    "        response.raise_for_status()\n",
    "    return response.json().get('data').get('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = {\n",
    "    'staging':\n",
    "    'production':\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO migrate one day the payloads to data model classes and refactor to classes following inheritance\n",
    "#from typing import List\n",
    "#from pydantic import BaseModel, parse_obj_as\n",
    "# class DatasetModel(BaseModel):\n",
    "\n",
    "# class LayerModel(BaseModel):\n",
    "\n",
    "# class widgetModel(BaseModel):\n",
    "\n",
    "# class metadataModel(BaseModel):\n",
    "     \n",
    "# class vocabularyModel(BaseModel):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAssets(url, payload):\n",
    "    response = re.get(url, payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def deleteAssets(url):\n",
    "    response = re.delete(url, headers = {'Authorization':f'Bearer {token}'})\n",
    "    response.raise_for_status()\n",
    "    return response.status_code\n",
    "\n",
    "def postAssets(url, body):\n",
    "    response = re.post(url, data=json.dumps(body), headers = {'Authorization':f'Bearer {token}', 'Content-Type': 'application/json'})\n",
    "    if response.status_code !=200:\n",
    "        print(response.text)\n",
    "        print(url)\n",
    "        print(json.dumps(body))\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def updateAssets(url, body):\n",
    "    response = re.patch(url, data=json.dumps(body), headers = {'Authorization':f'Bearer {token}', 'Content-Type': 'application/json'})\n",
    "    if response.status_code !=200:\n",
    "        print(response.text)\n",
    "        print(url)\n",
    "        print(json.dumps(body))\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def recreateDataset(dataset, toEnv = 'prod', destinationDatasetId = None):\n",
    "    \n",
    "    serverUrl = {\n",
    "        'prod': staging_server,\n",
    "        'staging': prod_server\n",
    "    }\n",
    "    if dataset.get('type')!='dataset':\n",
    "        return None\n",
    "    \n",
    "    url = f'{serverUrl[env]}/v1/dataset/{destinationDatasetId}'\n",
    "    body = {'dataset':{\n",
    "        'application': dataset['attributes'].get('application'),\n",
    "        'name': dataset['attributes'].get('name'),\n",
    "        'connectorType': dataset['attributes'].get('connectorType'),\n",
    "        'provider': dataset['attributes'].get('provider'),\n",
    "        'published': dataset['attributes'].get('published'),\n",
    "        'overwrite': dataset['attributes'].get('overwrite'),\n",
    "        'mainDateField': dataset['attributes'].get('mainDateField'),\n",
    "        'env': dataset['attributes'].get('env'),\n",
    "        'geoInfo': dataset['attributes'].get('geoInfo'),\n",
    "        'protected': dataset['attributes'].get('protected'),\n",
    "        'legend': dataset['attributes'].get('legend'),\n",
    "        'widgetRelevantProps': dataset['attributes'].get('widgetRelevantProps'),\n",
    "        'layerRelevantProps': dataset['attributes'].get('layerRelevantProps')\n",
    "        }\n",
    "    }\n",
    "    if dataset['attributes'].get('provider') == 'cartodb':\n",
    "            body['dataset']['connectorUrl'] =  dataset['attributes'].get('connectorUrl')\n",
    "    if dataset['attributes'].get('provider') == 'gee':\n",
    "            body['dataset']['tableName'] =  dataset['attributes'].get('tableName')\n",
    "    \n",
    "    if destinationDatasetId:\n",
    "        return updateAssets(url, body)\n",
    "    else:\n",
    "        return postAssets(url, body)\n",
    "    \n",
    "    \n",
    "\n",
    "def recreateLayer(datasetId, layer, toEnv = 'prod', destinationLayerId = None):\n",
    "    \n",
    "    serverUrl = {\n",
    "        'prod': staging_server,\n",
    "        'staging': prod_server\n",
    "    }\n",
    "    if layer.get('type')!='layer':\n",
    "        return None\n",
    "    \n",
    "    url = f'{serverUrl[env]}/v1/dataset/{datasetId}/layer/{destinationLayerId}'\n",
    "\n",
    "    body = {\n",
    "        'application': layer['attributes'].get('application'),\n",
    "        'name': layer['attributes'].get('name'),\n",
    "        'iso': layer['attributes'].get('iso'),\n",
    "        'provider': layer['attributes'].get('provider'),\n",
    "        'default': layer['attributes'].get('default'),\n",
    "        'protected': layer['attributes'].get('protected'),\n",
    "        'published': layer['attributes'].get('published'),\n",
    "        'env': layer['attributes'].get('env'),\n",
    "        'layerConfig': layer['attributes'].get('layerConfig'),\n",
    "        'legendConfig': layer['attributes'].get('legendConfig'),\n",
    "        'interactionConfig': layer['attributes'].get('interactionConfig'),\n",
    "        'applicationConfig': layer['attributes'].get('applicationConfig'),\n",
    "        'staticImageConfig': layer['attributes'].get('staticImageConfig')\n",
    "    }\n",
    "    \n",
    "    if destinationLayerId:\n",
    "        return updateAssets(url, body)\n",
    "    else:\n",
    "        return postAssets(url, body)\n",
    "\n",
    "def recreateWidget(datasetId, widget, toEnv = 'prod', destinationWidgetId = None):\n",
    "    \n",
    "    serverUrl = {\n",
    "        'prod': staging_server,\n",
    "        'staging': prod_server\n",
    "    }\n",
    "    \n",
    "    if widget.get('type')!='widget':\n",
    "        return None\n",
    "    \n",
    "    url = f'{serverUrl[env]}/v1/dataset/{datasetId}/widget/{destinationWidgetId}'\n",
    "    body = {\n",
    "        'application': widget['attributes'].get('application'),\n",
    "        'name': widget['attributes'].get('name'),\n",
    "        'description': widget['attributes'].get('description'),\n",
    "        'verified': widget['attributes'].get('verified'),\n",
    "        'default': widget['attributes'].get('default'),\n",
    "        'protected': widget['attributes'].get('protected'),\n",
    "        'defaultEditableWidget': widget['attributes'].get('defaultEditableWidget'),\n",
    "        'published': widget['attributes'].get('published'),\n",
    "        'freeze': widget['attributes'].get('freeze'),\n",
    "        'env': widget['attributes'].get('env'),\n",
    "        'queryUrl': widget['attributes'].get('queryUrl'),\n",
    "        'widgetConfig': widget['attributes'].get('widgetConfig'),\n",
    "        'template': widget['attributes'].get('template'),\n",
    "        'layerId': widget['attributes'].get('layerId')\n",
    "    }\n",
    "    if destinationWidgetId:\n",
    "        return updateAssets(url, body)\n",
    "    else:\n",
    "        return postAssets(url, body)\n",
    "\n",
    "def recreateMetadata(datasetId, metadata, layerId=None, widgetId=None, toEnv = 'prod'):\n",
    "    \n",
    "    serverUrl = {\n",
    "        'prod': staging_server,\n",
    "        'staging': prod_server\n",
    "    }\n",
    "    \n",
    "    if metadata.get('type')!='metadata':\n",
    "        return None\n",
    "    if layerId and widgetId:\n",
    "        raise Exception(\"layerId and widgetId not allowed at the same time\")\n",
    "    elif layerId:\n",
    "        url = f'{serverUrl[env]}/v1/dataset/{datasetId}/layer/{layerId}/metadata'\n",
    "    elif widgetId:\n",
    "        url = f'{serverUrl[env]}/v1/dataset/{datasetId}/widget/{widgetId}/metadata'\n",
    "    else:\n",
    "        url = f'{serverUrl[env]}/v1/dataset/{datasetId}/metadata'\n",
    "    \n",
    "    body = {\n",
    "        'application': metadata['attributes'].get('application'),\n",
    "        'language': metadata['attributes'].get('language'),\n",
    "        'description': metadata['attributes'].get('description'),\n",
    "        'info': metadata['attributes'].get('info'),\n",
    "    }\n",
    "    if metadata['attributes'].get('name'):\n",
    "        body['name'] = metadata['attributes'].get('name')\n",
    "    \n",
    "    try:\n",
    "        response = postAssets(url, body)\n",
    "    except Exception as e:\n",
    "        response = updateAssets(url, body)\n",
    "        pass\n",
    "    \n",
    "    return response\n",
    "\n",
    "def recreateVocabulary(datasetId, vocabulary, toEnv = 'prod'):\n",
    "    \n",
    "    serverUrl = {\n",
    "        'prod': staging_server,\n",
    "        'staging': prod_server\n",
    "    }\n",
    "    \n",
    "    if vocabulary.get('type')!='vocabulary':\n",
    "        return None\n",
    "    url = f\"{serverUrl[env]}/v1/dataset/{datasetId}/vocabulary/{vocabulary['attributes']['name']}\"\n",
    "    body = {\n",
    "        'application': vocabulary['attributes'].get('application'),\n",
    "        'tags': vocabulary['attributes'].get('tags')\n",
    "    }\n",
    "    \n",
    "    response = postAssets(url, body)\n",
    "    return response\n",
    "\n",
    "def getAssetList(Env = 'prod', datasetList=None):\n",
    "    serverUrl = {\n",
    "        'prod': staging_server,\n",
    "        'staging': prod_server\n",
    "    }\n",
    "    url = f'{serverUrl[env]}/v1/dataset'\n",
    "    payload={\n",
    "        'application':'rw',\n",
    "        'status':'saved',\n",
    "        'published':'true',\n",
    "        'includes':'widget,layer,vocabulary,metadata',\n",
    "        'page[size]':1613982331640\n",
    "    }\n",
    "    if datasetList:\n",
    "        payload['ids'] = datasetList\n",
    "        return postAssets(url,payload)\n",
    "    else:\n",
    "        return getAssets(url,payload)\n",
    "    \n",
    "def backupAssets(Env = 'prod'):\n",
    "    '''\n",
    "    save a backup of production data just in case we need to recreate it again\n",
    "    '''\n",
    "    \n",
    "    serverUrl = {\n",
    "        'prod': staging_server,\n",
    "        'staging': prod_server\n",
    "    }\n",
    "    url = f'{serverUrl[env]}/v1/dataset'\n",
    "    payload = {\n",
    "        'application':'rw',\n",
    "        'status':'saved',\n",
    "        'published':'true',\n",
    "        'includes':'widget,layer,vocabulary,metadata',\n",
    "        'page[size]':1613982331640\n",
    "    }\n",
    "\n",
    "    data = getAssets(url,payload)\n",
    "\n",
    "    with open(f'RW_{Env}_backup_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "\n",
    "def deleteDataFrom(env='staging'):\n",
    "    serverUrl = {\n",
    "        #'prod': staging_server,\n",
    "        'staging': prod_server\n",
    "    }\n",
    "    userConfirmation = input(f'{bcolors.WARNING}Are you sure you want to delete everything in {env}:{bcolors.ENDC} Y/n')\n",
    "    if userConfirmation == 'Y':\n",
    "        for dataset in prodData['data']:\n",
    "            try:\n",
    "                status = deleteAssets(f\"{staging_server}/v1/dataset/{dataset['id']}\")\n",
    "            except re.exceptions.HTTPError as err:\n",
    "                pass\n",
    "\n",
    "def copyAssets(datasetList, fromEnv='prod', toEnv='staging'):\n",
    "    dataAssets = getAssetList(Env = fromEnv, datasetList = datasetList)\n",
    "    if fromEnv == toEnv:\n",
    "        raise NameError(f'fromEnv:{fromEnv} and toEnv:{toEnv} cannot be the same')\n",
    "    try:\n",
    "        resources=[]\n",
    "        # @TODO:\n",
    "        # Improve loop performance\n",
    "        for dataset in dataAssets['data']:\n",
    "\n",
    "            newDataset = recreateDataset(dataset)\n",
    "\n",
    "            resources.append({\n",
    "                'type': 'dataset',\n",
    "                f'{fromEnv}Id':dataset.get('id'),\n",
    "                f'{toEnv}Id': newDataset['data'].get('id')\n",
    "            })\n",
    "\n",
    "            for vocabulary in dataset['attributes'].get('vocabulary'):\n",
    "                newVocabulary = recreateVocabulary(newDataset['data'].get('id'), vocabulary)\n",
    "                resources.append({\n",
    "                'type': 'vocabulary',\n",
    "                f'{fromEnv}Id':vocabulary.get('id'),\n",
    "                f'{toEnv}Id': newVocabulary['data']\n",
    "            })\n",
    "\n",
    "            for layer in dataset['attributes'].get('layer'):\n",
    "                newLayer = recreateLayer(newDataset['data'].get('id'), layer)\n",
    "                resources.append({\n",
    "                'type': 'layer',\n",
    "                f'{fromEnv}Id':layer.get('id'),\n",
    "                f'{toEnv}Id': newLayer['data'].get('id')\n",
    "            })\n",
    "\n",
    "            for widget in dataset['attributes'].get('widget'):\n",
    "                newWidget = recreateWidget(newDataset['data'].get('id'), widget)\n",
    "                resources.append({\n",
    "                'type': 'widget',\n",
    "                f'{fromEnv}Id':widget.get('id'),\n",
    "                f'{toEnv}Id': newWidget['data'].get('id')\n",
    "            })\n",
    "\n",
    "            for metadata in dataset['attributes'].get('metadata'):\n",
    "                newMetadata = recreateMetadata(newDataset['data'].get('id'), metadata)\n",
    "                resources.append({\n",
    "                'type': 'metadata',\n",
    "                f'{fromEnv}Id':metadata.get('id'),\n",
    "                f'{toEnv}Id': newMetadata['data']\n",
    "            })\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    with open(f'RW_prod_staging_match_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.json', 'w') as outfile:\n",
    "        json.dump(resources, outfile)\n",
    "        \n",
    "def syncAssets(syncList, fromEnv='prod', toEnv='staging'):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of assets that we want to modify or sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of assets:\n",
    "\n",
    "* we need to make sure that this list is in sync with the document we have shared with the assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the future we can automate this listing base on the doc using the google sheet api\n",
    "datasetsProd = []\n",
    "layersProd = []\n",
    "widgetsProd = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backup Data in both environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'backupAssets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ffeac75cb754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbackupAssets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'backupAssets' is not defined"
     ]
    }
   ],
   "source": [
    "backupAssets('prod')\n",
    "backupAssets('staging')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only do this if you want to clean data in staging. \n",
    "*You will need to be logged in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleteDataFrom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy resources from production to staging. Depending on the asset size this operation might take time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-4f56ea9b8123>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-4f56ea9b8123>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def copyAssets(fromEnv=  'prod', toEnv= 'staging', datasetList)\u001b[0m\n\u001b[0m                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "copyAssets(datasetList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open sync list of assets match it with list and update it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
